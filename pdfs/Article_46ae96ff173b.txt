These days, left and right you see people talking about how AI can just do anything instantly, single shot. No need for radiologists anymore, AI can do it better. No need for website designers — AI can just build you whatever website you want in a single prompt. No need for Hollywood animators, you can just use AI to generate your images and videos instead. Problem solved!

But of course, real life doesn’t work that way, despite LinkedIn influencers pretending it does. In the real world, things are messy and complicated. Edge cases dominate, and something that works only most of the time is cute for a pitch deck, but not something that will satisfy customers who need a reliable service that doesn’t complicate their life.

So whenever I hear someone talking about how easy doing X is these days, using the latest ChatGPT or Gemini model, I can’t help but roll my eyes. AI is amazing, don’t get me wrong, but it’s not a magic bullet for everything. These LLM models are great for first impressions, no doubt. They are great at creating the illusion that they can solve a problem. But the moment you start testing on real-world inputs instead of cherry-picked demo prompts, reality hits: AI goes from ‘this changes everything’ to ‘this barely works.’

I’m not saying we just chuck it all into the garbage. Far from it. But what I am saying, is that going from 80% to 99% is hard. A lot of engineering is needed to properly wrap these AI models into a system that is cohesive, reliable, and ultimately: useful to people.

So while you can whip up a quick and dirty demo using a single prompt, building a real world system requires many boring levels of complication. In other words, that last 19% is where you’ll spend most of your time. Here are some examples, from our experience at DocuPanda:

We all started once as bright eyed and bushy tailed builders, full of the hope and vision of what AI will let us create for users, and the endless piles of money that will inevitably on our heads as a result. But then as you start the journey, getting users, iterating on your product, fixing all the endless bugs and edge cases, you start getting a bit jaded. Where once you were sure that AGI was here and everything is solved, suddenly you mutter “these things are so stupid” while stress eating a sandwich. Nothing is more sobering than tediously reviewing all the ways an LLM can still muck things up.

But to quote Lester from The Wire: “This right here, this is the job.” This is the work that needs to be done. The inglorious work of being a plumber, of painstakingly engineering a complete system that abstracts away from the user all of the modes of failure, and just exposes a clean, simple, and useful product.

This is what we spend our time over at DocuPanda doing. While some people are convinced that parsing PDFs into text and then converting them to a structured format is a “solved problem”, and any one of the many LLM vendors just solve this in a single shot, we’ve learned the hard way that the hype is not to be believed. So we spend our time poring over failure cases, improving the product, talking to users, figuring out what is still broken, and trying to make it better. We don’t chase the illusion of single-shot perfection — we build the infrastructure that makes AI actually work for businesses.

I once thought that it would be relatively simple to get things working 100%, no problem, give me 2 weeks. But reality taught me once again, for the hundredth time, that things are always harder than they seem. The road from 80% to 99% isn’t glamorous — but it’s the difference between dream and reality. And the people who solve it? They’re the ones actually building the future.